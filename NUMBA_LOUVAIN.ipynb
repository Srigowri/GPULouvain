{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NUMBA_LOUVAIN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPd5Kxrovx0YnHPF+I5rMAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srigowri/GPULouvain/blob/main/NUMBA_LOUVAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cInzT24KtJ-J"
      },
      "source": [
        "\n",
        "Created on Sun Jun  6 19:16:05 2021\n",
        "\n",
        "@author: srigowri\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSBe7VYwtHED"
      },
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numba import vectorize,jit\n",
        "import time\n",
        "from numba import cuda\n",
        "import numba\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import scipy.sparse as ss\n",
        "from numba.experimental import jitclass\n",
        "# from numba import int32, float32\n",
        "from numba import jitclass, types, typed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23U9UL-j1kc7"
      },
      "source": [
        "MAXIMUM_PASSES = -1\n",
        "MIN_MODULARITY = 0.0000001\n",
        "\n",
        "\n",
        "# self.node2com = typed.List.empty_list(numba.types.uint32,self.N-1)\n",
        "# print(\"here--2\")\n",
        "# self.degrees = typed.List.empty_list(numba.types.uint32,self.N-1)\n",
        "# print(\"here--3\")\n",
        "# self.gdegrees = typed.List.empty_list( numba.types.uint32,self.N-1)\n",
        "# print(\"here--4\")\n",
        "# self.internals = typed.List.empty_list(numba.types.uint32,self.N-1)\n",
        "# print(\"here--5\")\n",
        "# self.total_weight = (np.sum(self.data) + np.sum(self.diagonal))//2\n",
        "# print(\"here--6\")\n",
        "# self.loops = typed.List.empty_list(np.uint32,self.N-1)\n",
        "# print(\"here--7\")\n",
        "\n",
        "# spec = [\n",
        "#     ('resolution', numba.types.float64),     \n",
        "#     ('weight_key', numba.types.unicode_type), \n",
        "#     ('diagonal',numba.types.int64[::1]),\n",
        "#     ('indices',numba.types.uint64[::1]),\n",
        "#     ('indptr',numba.types.uint64[::1]),\n",
        "#     ('data',numba.types.float64[::1]),\n",
        "#     ('N',numba.types.uint64),\n",
        "#     ('count',numba.types.uint64),\n",
        "#     ('node2com', numba.types.int64[::1]),\n",
        "#     ('degrees', numba.types.int64[::1]),\n",
        "#     ('gdegrees', numba.types.int64[::1]),\n",
        "#     ('internals', numba.types.int64[::1]),\n",
        "#     ('total_weight', numba.types.float64),\n",
        "#     ('loops', numba.types.int64[::1]),\n",
        "# ]\n",
        "    \n",
        "\n",
        "\n",
        "# @jitclass(spec)\n",
        "class LouvainCSR():\n",
        "    def __init__(self,resolution=1.0,weight_key='weight'):\n",
        "        \n",
        "        self.resolution = resolution\n",
        "        self.weight_key = weight_key\n",
        "        \n",
        "            \n",
        "    def init_graph_param(self,indices,indptr,data,diagonal):                \n",
        "\n",
        "        self.diagonal = diagonal\n",
        "        self.indices = indices\n",
        "        self.indptr = indptr\n",
        "        self.data = data\n",
        "        self.N = self.indptr.size\n",
        "        self.count = 0\n",
        "        self.node2com = np.zeros(self.N-1,dtype = np.int64)\n",
        "        self.degrees = np.zeros(self.N-1,dtype = np.uint64)\n",
        "        self.gdegrees = np.zeros(self.N-1,dtype = np.uint64)\n",
        "        self.internals = np.zeros(self.N-1,dtype = np.uint64)\n",
        "        self.total_weight = np.float64((np.sum(self.data) + np.sum(self.diagonal))//2)\n",
        "        self.loops = np.zeros(self.N-1,dtype = np.uint64)\n",
        "\n",
        "            \n",
        "        for node in range(self.N-1):\n",
        "                    \n",
        "            self.node2com[node] = self.count                        \n",
        "            deg = np.sum(self.data[self.indptr[node] : self.indptr[node+1]])            \n",
        "            self.degrees[self.count] = deg + self.diagonal[node]\n",
        "            self.gdegrees[node] = deg + self.diagonal[node]\n",
        "            self.loops[node] = self.diagonal[node]\n",
        "            self.internals[self.count] = self.loops[node]\n",
        "            self.count += 1\n",
        "            \n",
        "    \n",
        "    def modularity(self):\n",
        "        links = numba.float32(self.total_weight)\n",
        "        result = 0.\n",
        "        if links > 0: \n",
        "            for community in set(self.node2com):\n",
        "                in_degree = self.internals[int(community)]\n",
        "                degree =   self.degrees[int(community)]\n",
        "                result += (in_degree * self.resolution / links) -  ((degree / (2. * links)) ** 2)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def randomize(items):\n",
        "        randomized_items = list(items)\n",
        "        np.random.shuffle(randomized_items)\n",
        "        # cp.random.shuffle(cp.array(randomized_items))\n",
        "        return randomized_items\n",
        "\n",
        "    \n",
        "    def neighcom(self,node):\n",
        "        \"\"\"\n",
        "        Compute the communities in the neighborhood of node in the graph given\n",
        "        with the decomposition node2com\n",
        "        \"\"\"\n",
        "        weights = np.zeros(self.node2com.size)\n",
        "        neighbours = self.indices[self.indptr[node] : self.indptr[node+1]]\n",
        "        attributes = self.data[self.indptr[node] : self.indptr[node+1]]\n",
        "        for neighbor,edge_weight in zip(neighbours,attributes):\n",
        "            if neighbor!=node:\n",
        "                neighborcom = self.node2com[neighbor]\n",
        "                weights[neighborcom] = weights[neighborcom] + edge_weight\n",
        "        return weights\n",
        "\n",
        "    \n",
        "    def remove(self,node, community, weight):\n",
        "        \"\"\" Remove node from community com and modify status\"\"\"\n",
        "        self.degrees[community] = (self.degrees[community] - self.gdegrees[node])\n",
        "        self.internals[community] = float(self.internals[community] - weight - self.loops[node])\n",
        "        self.node2com[node] = -1\n",
        "\n",
        "    \n",
        "    def insert(self,node, community, weight):\n",
        "        \"\"\" Insert node into community and modify status\"\"\"\n",
        "        self.node2com[node] = community\n",
        "        self.degrees[community] = (self.degrees[community] + self.gdegrees[node])\n",
        "        self.internals[community] = float(self.internals[community] + weight + self.loops[node])\n",
        "\n",
        "    \n",
        "    def first_phase(self):\n",
        "        \"\"\"Compute one level of communities\n",
        "        \"\"\"\n",
        "        modified = True\n",
        "        nb_pass_done = 0\n",
        "        new_mod = self.modularity()\n",
        "        \n",
        "\n",
        "        while modified and nb_pass_done != MAXIMUM_PASSES:\n",
        "            cur_mod = new_mod\n",
        "            modified = False\n",
        "            nb_pass_done += 1\n",
        "#            allnodes = LouvainCSR.randomize(range(self.N-1))\n",
        "            for node in range(self.N-1):\n",
        "                com_node = self.node2com[node]\n",
        "                degc_totw = self.gdegrees[node] / (self.total_weight * 2.)  # NOQA    \n",
        "                neigh_communities = self.neighcom(node)                \n",
        "                remove_cost = - self.resolution * neigh_communities[com_node] + (self.degrees[com_node] - self.gdegrees[node]) * degc_totw\n",
        "                               \n",
        "                self.remove(node, com_node,neigh_communities[com_node])                \n",
        "                best_com = com_node\n",
        "                best_increase = 0\n",
        "#                LouvainCSR.randomize(zip(range(self.N),neigh_communities)):\n",
        "                nonzero_idx = np.nonzero(neigh_communities)[0]\n",
        "                \n",
        "                for com, dnc in zip(nonzero_idx,neigh_communities[nonzero_idx]):\n",
        "                    incr = remove_cost + self.resolution * dnc - self.degrees[com] * degc_totw\n",
        "                    \n",
        "                    if incr > best_increase:\n",
        "                        best_increase = incr\n",
        "                        best_com = com\n",
        "                \n",
        "                self.insert(node, best_com,neigh_communities[best_com])\n",
        "                \n",
        "                if best_com != com_node:\n",
        "                    modified = True\n",
        "                    \n",
        "            new_mod = self.modularity()\n",
        "            if new_mod - cur_mod < MIN_MODULARITY:\n",
        "                break\n",
        "\n",
        "    \n",
        "    def induced_graph(self,partition):\n",
        "\n",
        "        ret = nx.Graph()\n",
        "        ret.add_nodes_from(partition)\n",
        "        seen = set()\n",
        "        nodelist = set(ret.nodes())\n",
        "        for node1 in range(self.N-1):\n",
        "            neighbours = self.indices[self.indptr[node1] : self.indptr[node1+1]]                       \n",
        "            attributes = self.data[self.indptr[node1] : self.indptr[node1+1]]\n",
        "            com1 = partition[node1]\n",
        "            for node2, edge_weight in zip(neighbours,attributes):  \n",
        "                if (node1,node2) not in seen and (node2,node1) not in seen:\n",
        "                    com2 = partition[node2]          \n",
        "#                    print((com1,com2))\n",
        "                    w_prec = ret.get_edge_data(com1, com2, {self.weight_key: 0}).get(self.weight_key, 1)\n",
        "                    ret.add_edge(com1, com2, **{self.weight_key: w_prec + edge_weight})                                \n",
        "                    seen.add((node1,node2))\n",
        "                    \n",
        "        csr = nx.convert_matrix.to_scipy_sparse_matrix(ret,nodelist=nodelist,weight=self.weight_key)#,ret.nodes())                                                 \n",
        "        return csr\n",
        "                           \n",
        "    @staticmethod\n",
        "    def renumber(partition):\n",
        "        \"\"\"Renumber the values of the dictionary from 0 to n\n",
        "        \"\"\"\n",
        "        values = set(partition)\n",
        "        target = set(range(len(values)))\n",
        "\n",
        "        if values != target:\n",
        "            # add the values that won't be renumbered\n",
        "            renumbering = dict(zip(target.intersection(values),\n",
        "                                target.intersection(values)))\n",
        "            # add the values that will be renumbered\n",
        "            renumbering.update(dict(zip(values.difference(target),\n",
        "                                        target.difference(values))))\n",
        "            \n",
        "            for i in range(len(partition)):\n",
        "                partition[i] = renumbering[partition[i]]\n",
        "        \n",
        "        return partition\n",
        "\n",
        "    @staticmethod\n",
        "    def partition_at_level1(dendograms, level):\n",
        "        partition = dendograms[0].copy()\n",
        "        for index in range(1, level + 1):\n",
        "        \n",
        "            for node, community in enumerate(partition):\n",
        "                partition[node] = dendograms[index][community]\n",
        "\n",
        "        return partition\n",
        "\n",
        "\n",
        "def detect_communities(indices,indptr,data,diagonal,weight_key='weight',resolution=1.0):\n",
        "#    if graph.is_directed():\n",
        "#        raise TypeError(\"Modularity is undefined for directed graph\")\n",
        "#    \n",
        "#    edges = graph.number_of_edges()\n",
        "#    if edges == 0:\n",
        "#        return {node: i for i, node in enumerate(graph.nodes())}\n",
        "    \n",
        "    dendograms = []      \n",
        "    louvain1 = LouvainCSR(resolution,weight_key)    \n",
        "\n",
        "\n",
        "    louvain1.init_graph_param(indices,indptr,data,diagonal)    \n",
        "    louvain1.first_phase()    \n",
        "    prev_modularity = louvain1.modularity()            \n",
        "    partition = LouvainCSR.renumber(louvain1.node2com)    \n",
        "    dendograms.append(partition)\n",
        "    current_graph = louvain1.induced_graph(partition)\n",
        "    louvain1.init_graph_param(current_graph.indices,current_graph.indptr,current_graph.data,current_graph.diagonal())\n",
        "\n",
        "\n",
        "    while True:\n",
        "        louvain1.first_phase()\n",
        "        new_modularity = louvain1.modularity()  \n",
        "        # print(\"modularity\",new_modularity)        \n",
        "        if abs(new_modularity - prev_modularity) < MIN_MODULARITY:\n",
        "            break    \n",
        "        prev_modularity = new_modularity\n",
        "        partition = LouvainCSR.renumber(louvain1.node2com)\n",
        "        dendograms.append(partition)\n",
        "        current_graph = louvain1.induced_graph(partition)\n",
        "        louvain1.init_graph_param(current_graph.indices,current_graph.indptr,current_graph.data,current_graph.diagonal())\n",
        "\n",
        "    return LouvainCSR.partition_at_level1(dendograms,len(dendograms)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_KVrL3OuS1Z"
      },
      "source": [
        "#@title\n",
        "@jit(nopython=True,parallel = True)\n",
        "def modularity(partition,indices,indptr,data,edges,all_communities):\n",
        "    within_community_degree = np.zeros(all_communities.size)\n",
        "    total_community_degree = np.zeros(all_communities.size)\n",
        "\n",
        "    for i in range(indptr.size-1):\n",
        "        neighbours = indices[indptr[i] : indptr[i+1]]\n",
        "        attributes = data[indptr[i] : indptr[i+1]]\n",
        "        community = partition[i]\n",
        "        total_community_degree[community] += len(neighbours)\n",
        "        for n,a in zip(neighbours,attributes):\n",
        "            if partition[n]== community:\n",
        "                within_community_degree[community] += (a if n == i else a /2)\n",
        "    \n",
        "#    mod = 0.0\n",
        "#    for community in all_communities:\n",
        "#        mod += ((within_community_degree[community]/(edges))-(total_community_degree[community]/(2*edges)) ** 2)\n",
        "#    \n",
        "#    \n",
        "    mod = np.sum((within_community_degree/(edges))-(total_community_degree/(2*edges)) ** 2)\n",
        "    return mod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3icHNHAzukgd"
      },
      "source": [
        "**ZACHARY KARATE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpg1switevLl",
        "outputId": "0f6e7c59-852e-4d6c-f902-f3c88001976c"
      },
      "source": [
        "type(csr_graph.indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wToIG7O_jDcx",
        "outputId": "ab9a4602-8cd8-4a54-b335-ad6cd621da0b"
      },
      "source": [
        "len(csr_graph.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2W2DkOstTr_",
        "outputId": "384254aa-8ed9-47ae-a061-9d5b00ff5758"
      },
      "source": [
        "g = nx.karate_club_graph()\n",
        "csr_graph = nx.convert_matrix.to_scipy_sparse_matrix(g)\n",
        "part = detect_communities(csr_graph.indices,csr_graph.indptr,csr_graph.data,csr_graph.diagonal())\n",
        "print(part)\n",
        "all_communities = np.array(list(set(part)))\n",
        "edges= len(csr_graph.indices)//2\n",
        "%timeit modularity(part,csr_graph.indices,csr_graph.indptr,csr_graph.data,edges,all_communities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 3 3 3 1 0 1 3 1 1 1 0 0 3 1 0 1 0 1 0 2 2 2 0 2 2 0 0 2 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 158209.01 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 8.59 Âµs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQKlyidfuhke"
      },
      "source": [
        "def read_data_file_as_coo_matrix(filename='edges.txt'):\n",
        "    \"Read data file and return sparse matrix in coordinate format.\"\n",
        "    data = pd.read_csv(filename, sep=' ', header=None, dtype=np.uint64)\n",
        "    data = pd.concat([data,pd.DataFrame(list(zip(data[1],data[0])))],axis=0)\n",
        "    \n",
        "    rows = data[0]  # Not a copy, just a reference.\n",
        "    cols = data[1]\n",
        "    \n",
        "    ones = np.ones(len(rows), np.uint64)\n",
        "    \n",
        "    matrix = ss.coo_matrix((ones, (rows, cols)))\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def save_csr_matrix(filename, matrix):\n",
        "    \"\"\"Save compressed sparse row (csr) matrix to file.\n",
        "\n",
        "    Based on http://stackoverflow.com/a/8980156/232571\n",
        "\n",
        "    \"\"\"\n",
        "    assert filename.endswith('.npz')\n",
        "    attributes = {\n",
        "        'data': matrix.data,\n",
        "        'indices': matrix.indices,\n",
        "        'indptr': matrix.indptr,\n",
        "        'shape': matrix.shape,\n",
        "    }\n",
        "    np.savez(filename, **attributes)\n",
        "\n",
        "def load_csr_matrix(filename):\n",
        "    \"\"\"Load compressed sparse row (csr) matrix from file.\n",
        "\n",
        "    Based on http://stackoverflow.com/a/8980156/232571\n",
        "\n",
        "    \"\"\"\n",
        "    assert filename.endswith('.npz')\n",
        "    loader = np.load(filename)\n",
        "    args = (loader['data'], loader['indices'], loader['indptr'])\n",
        "    matrix = ss.csr_matrix(args, shape=loader['shape'])\n",
        "    return matrix\n",
        "\n",
        "\n",
        "\"Test data file parsing and matrix serialization.\"\n",
        "\n",
        "coo_matrix = read_data_file_as_coo_matrix(\"facebook_combined.txt\")\n",
        "csr_graph = coo_matrix.tocsr()\n",
        "# save_csr_matrix(\"facebook_csr.npz\", csr_graph)\n",
        "# loaded_csr_matrix = load_csr_matrix(\"facebook_csr.npz\")\n",
        "# assert (csr_graph != loaded_csr_matrix).nnz == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN9PZQpbvPHl",
        "outputId": "6492a3d7-3d78-4308-af83-b539c71e572c"
      },
      "source": [
        "# part = detect_communities(csr_graph)\n",
        "# all_communities = np.array(list(set(part)))\n",
        "# edges = len(csr_graph.indices)//2\n",
        "%timeit modularityCP(part,csr_graph.indices,csr_graph.indptr,csr_graph.data,edges,all_communities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 1.37 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}